{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T12:35:53.112204Z",
     "start_time": "2025-02-26T12:35:41.172578Z"
    }
   },
   "cell_type": "code",
   "source": [
    "!torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 6601 /root/autodl-tmp/finetune.py \\\n",
    "    --model_name_or_path \"/root/autodl-fs/DeepSeek-R1-Distill-Qwen-32B\" \\\n",
    "    --data_path \"/root/autodl-tmp-data/datasets/output.json\" \\\n",
    "    --bf16 True \\\n",
    "    --output_dir \"/root/autodl-fs/trained_models/deepseek_ri_32b_sop\" \\\n",
    "    --num_train_epochs 50 \\\n",
    "    --per_device_train_batch_size 8 \\\n",
    "    --per_device_eval_batch_size 8 \\\n",
    "    --gradient_accumulation_steps 16 \\\n",
    "    --evaluation_strategy \"no\" \\\n",
    "    --save_strategy \"steps\" \\\n",
    "    --save_steps 902 \\\n",
    "    --save_total_limit 1 \\\n",
    "    --learning_rate 1e-5 \\\n",
    "    --weight_decay 0.1 \\\n",
    "    --adam_beta2 0.95 \\\n",
    "    --warmup_ratio 0.01 \\\n",
    "    --lr_scheduler_type \"cosine\" \\\n",
    "    --logging_steps 1 \\\n",
    "    --report_to \"none\" \\\n",
    "    --model_max_length 512 \\\n",
    "    --gradient_checkpointing True \\\n",
    "    --lazy_preprocess True \\\n",
    "    --deepspeed \"/root/autodl-tmp/deepspeed/ds_config_zero2.json\" \\\n",
    "    --use_lora"
   ],
   "id": "c6754e9b28a4867a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:torch.distributed.run:\r\n",
      "*****************************************\r\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \r\n",
      "*****************************************\r\n",
      "[2025-02-26 20:35:44,969] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)\r\n",
      "[2025-02-26 20:35:44,971] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)\r\n",
      "[2025-02-26 20:35:44,972] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)\r\n",
      "[2025-02-26 20:35:44,976] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)\r\n",
      "/root/miniconda3/lib/python3.8/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\r\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\r\n",
      "/root/miniconda3/lib/python3.8/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\r\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\r\n",
      "/root/miniconda3/lib/python3.8/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\r\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\r\n",
      "/root/miniconda3/lib/python3.8/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\r\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\r\n",
      "/root/miniconda3/lib/python3.8/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\r\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\r\n",
      "/root/miniconda3/lib/python3.8/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\r\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\r\n",
      "/root/miniconda3/lib/python3.8/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\r\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\r\n",
      "/root/miniconda3/lib/python3.8/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\r\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\r\n",
      "/root/miniconda3/lib/python3.8/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\r\n",
      "  warnings.warn(\r\n",
      "[2025-02-26 20:35:48,207] [INFO] [comm.py:658:init_distributed] cdb=None\r\n",
      "/root/miniconda3/lib/python3.8/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\r\n",
      "  warnings.warn(\r\n",
      "[2025-02-26 20:35:48,225] [INFO] [comm.py:658:init_distributed] cdb=None\r\n",
      "[2025-02-26 20:35:48,225] [INFO] [comm.py:689:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\r\n",
      "/root/miniconda3/lib/python3.8/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\r\n",
      "  warnings.warn(\r\n",
      "[2025-02-26 20:35:48,249] [INFO] [comm.py:658:init_distributed] cdb=None\r\n",
      "/root/miniconda3/lib/python3.8/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\r\n",
      "  warnings.warn(\r\n",
      "[2025-02-26 20:35:48,256] [INFO] [comm.py:658:init_distributed] cdb=None\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/root/autodl-tmp/finetune.py\", line 446, in <module>\r\n",
      "    train()\r\n",
      "  File \"/root/autodl-tmp/finetune.py\", line 354, in train\r\n",
      "    and deepspeed.is_deepspeed_zero3_enabled()\r\n",
      "AttributeError: module 'deepspeed' has no attribute 'is_deepspeed_zero3_enabled'\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/root/autodl-tmp/finetune.py\", line 446, in <module>\r\n",
      "    train()\r\n",
      "  File \"/root/autodl-tmp/finetune.py\", line 354, in train\r\n",
      "    and deepspeed.is_deepspeed_zero3_enabled()\r\n",
      "AttributeError: module 'deepspeed' has no attribute 'is_deepspeed_zero3_enabled'\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/root/autodl-tmp/finetune.py\", line 446, in <module>\r\n",
      "    train()\r\n",
      "  File \"/root/autodl-tmp/finetune.py\", line 354, in train\r\n",
      "    and deepspeed.is_deepspeed_zero3_enabled()\r\n",
      "AttributeError: module 'deepspeed' has no attribute 'is_deepspeed_zero3_enabled'\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/root/autodl-tmp/finetune.py\", line 446, in <module>\r\n",
      "    train()\r\n",
      "  File \"/root/autodl-tmp/finetune.py\", line 354, in train\r\n",
      "    and deepspeed.is_deepspeed_zero3_enabled()\r\n",
      "AttributeError: module 'deepspeed' has no attribute 'is_deepspeed_zero3_enabled'\r\n",
      "ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 1405) of binary: /root/miniconda3/bin/python\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/root/miniconda3/bin/torchrun\", line 8, in <module>\r\n",
      "    sys.exit(main())\r\n",
      "  File \"/root/miniconda3/lib/python3.8/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 346, in wrapper\r\n",
      "    return f(*args, **kwargs)\r\n",
      "  File \"/root/miniconda3/lib/python3.8/site-packages/torch/distributed/run.py\", line 794, in main\r\n",
      "    run(args)\r\n",
      "  File \"/root/miniconda3/lib/python3.8/site-packages/torch/distributed/run.py\", line 785, in run\r\n",
      "    elastic_launch(\r\n",
      "  File \"/root/miniconda3/lib/python3.8/site-packages/torch/distributed/launcher/api.py\", line 134, in __call__\r\n",
      "    return launch_agent(self._config, self._entrypoint, list(args))\r\n",
      "  File \"/root/miniconda3/lib/python3.8/site-packages/torch/distributed/launcher/api.py\", line 250, in launch_agent\r\n",
      "    raise ChildFailedError(\r\n",
      "torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \r\n",
      "============================================================\r\n",
      "/root/autodl-tmp/finetune.py FAILED\r\n",
      "------------------------------------------------------------\r\n",
      "Failures:\r\n",
      "[1]:\r\n",
      "  time      : 2025-02-26_20:35:52\r\n",
      "  host      : autodl-container-ea584aab82-91142a00\r\n",
      "  rank      : 1 (local_rank: 1)\r\n",
      "  exitcode  : 1 (pid: 1406)\r\n",
      "  error_file: <N/A>\r\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\r\n",
      "[2]:\r\n",
      "  time      : 2025-02-26_20:35:52\r\n",
      "  host      : autodl-container-ea584aab82-91142a00\r\n",
      "  rank      : 2 (local_rank: 2)\r\n",
      "  exitcode  : 1 (pid: 1407)\r\n",
      "  error_file: <N/A>\r\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\r\n",
      "[3]:\r\n",
      "  time      : 2025-02-26_20:35:52\r\n",
      "  host      : autodl-container-ea584aab82-91142a00\r\n",
      "  rank      : 3 (local_rank: 3)\r\n",
      "  exitcode  : 1 (pid: 1408)\r\n",
      "  error_file: <N/A>\r\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\r\n",
      "------------------------------------------------------------\r\n",
      "Root Cause (first observed failure):\r\n",
      "[0]:\r\n",
      "  time      : 2025-02-26_20:35:52\r\n",
      "  host      : autodl-container-ea584aab82-91142a00\r\n",
      "  rank      : 0 (local_rank: 0)\r\n",
      "  exitcode  : 1 (pid: 1405)\r\n",
      "  error_file: <N/A>\r\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\r\n",
      "============================================================\r\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "35acf008-1dfe-4d32-8cf5-7022e042aadb",
   "metadata": {},
   "source": "## 权重融合"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61021499-4a44-45af-a682-943ed63c2fcb",
   "metadata": {},
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "from peft import PeftModel\n",
    "import torch\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen-1_8B-Chat/\", torch_dtype=torch.float16, device_map=\"auto\", trust_remote_code=True)\n",
    "model = PeftModel.from_pretrained(model, \"output_qwen/\")\n",
    "merged_model = model.merge_and_unload()\n",
    "merged_model.save_pretrained(\"output_qwen_merged\", max_shard_size=\"2048MB\", safe_serialization=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "0dfbd261-6451-4532-82e8-3ae19ed93ee1",
   "metadata": {},
   "source": "## 分词器"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcba069-340b-4a93-a145-2028b425dd23",
   "metadata": {},
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"Qwen/Qwen-1_8B-Chat/\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "tokenizer.save_pretrained(\"output_qwen_merged\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "fe9f2878-79d3-4b1c-ba95-ac2f73aa6e1b",
   "metadata": {},
   "source": "## 模型测试"
  },
  {
   "cell_type": "code",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-02-26T11:49:14.690891Z"
    }
   },
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers.generation import GenerationConfig\n",
    "import torchvision\n",
    "\n",
    "torchvision.disable_beta_transforms_warning()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/root/autodl-fs/DeepSeek-R1-Distill-Llama-70B\", trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"/root/autodl-fs/DeepSeek-R1-Distill-Llama-70B\",\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ").eval()\n",
    "\n",
    "prompt = \"你好,你是谁？\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "response = tokenizer.decode(model.generate(**inputs, max_new_tokens=128000)[0], skip_special_tokens=True)\n",
    "print(response)"
   ],
   "id": "bc3f2a8586ad7424",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/17 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7524e6628bd74c919ca694e01df27152"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 选一条样本对训练出来的模型进行人工比对",
   "id": "89992b6b55790e2b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "{\n",
    "    \"conversations\": \n",
    "        [\n",
    "            {\n",
    "                \"from\": \"user\", \n",
    "                \"value\": \"你现在是一个很厉害的阅读理解器，严格按照人类指令进行回答。\\nInput: 下面描述中包含了哪些SPO？\\n返回json回答:\\n\\n花样男子花样男子《花样男子》，日文原名《花より男子》（Hana-yori Danshi），是日本漫画家神尾叶子的一部长篇爱情校园漫画，原作自1992年至2004年在集英社的漫画杂志《Margaret》上连载，并发行了37册的单行本，销量超过5900万册，霸占了日本第一畅销少女漫画的宝座。\"}, \n",
    "            {\n",
    "                \"from\": \"assistant\", \n",
    "                \"value\": \"[{\\\"predicate\\\": \\\"编剧\\\", \\\"object_type\\\": \\\"人物\\\", \\\"subject_type\\\": \\\"影视作品\\\", \\\"object\\\": \\\"神尾叶子\\\", \\\"subject\\\": \\\"花样男子\\\"}, {\\\"predicate\\\": \\\"出版社\\\", \\\"object_type\\\": \\\"出版社\\\", \\\"subject_type\\\": \\\"书籍\\\", \\\"object\\\": \\\"集英社\\\", \\\"subject\\\": \\\"花样男子\\\"}]\"\n",
    "            }\n",
    "        ], \n",
    "    \"id\": \"identity_0\"\n",
    "}"
   ],
   "id": "6aceadf2c3883c9b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
