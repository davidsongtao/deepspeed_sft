{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "torchrun --nproc_per_node 4 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 6601 /root/autodl-tmp/finetune.py \\\n",
    "    --model_name_or_path \"/root/autodl-fs/DeepSeek-R1-Distill-Qwen-32B\" \\\n",
    "    --data_path \"/root/autodl-tmp/data/datasets/output.json\" \\\n",
    "    --eval_data_path \"/root/autodl-tmp/data/datasets/dev.json\" \\\n",
    "    --bf16 True \\\n",
    "    --output_dir \"/root/autodl-fs/trained_models/deepseek_ri_32b_sop\" \\\n",
    "    --num_train_epochs 66 \\\n",
    "    --per_device_train_batch_size 12 \\\n",
    "    --per_device_eval_batch_size 12 \\\n",
    "    --gradient_accumulation_steps 1 \\\n",
    "    --eval_strategy \"steps\" \\\n",
    "    --eval_steps  100 \\\n",
    "    --metric_for_best_model \"eval_loss\" \\\n",
    "    --greater_is_better False \\\n",
    "    --save_strategy \"steps\" \\\n",
    "    --save_steps 666 \\\n",
    "    --load_best_model_at_end True \\\n",
    "    --save_total_limit 3 \\\n",
    "    --learning_rate 1e-5 \\\n",
    "    --weight_decay 0.1 \\\n",
    "    --adam_beta2 0.95 \\\n",
    "    --warmup_ratio 0.03 \\\n",
    "    --lr_scheduler_type \"cosine\" \\\n",
    "    --logging_steps 1 \\\n",
    "    --report_to \"none\" \\\n",
    "    --model_max_length 512 \\\n",
    "    --gradient_checkpointing True \\\n",
    "    --lazy_preprocess True \\\n",
    "    --deepspeed \"/root/autodl-tmp/deepspeed/ds_config_zero2.json\" \\\n",
    "    --use_lora"
   ],
   "id": "c6754e9b28a4867a",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "35acf008-1dfe-4d32-8cf5-7022e042aadb",
   "metadata": {},
   "source": "## 权重融合"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61021499-4a44-45af-a682-943ed63c2fcb",
   "metadata": {},
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "from peft import PeftModel\n",
    "import torch\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen-1_8B-Chat/\", torch_dtype=torch.float16, device_map=\"auto\", trust_remote_code=True)\n",
    "model = PeftModel.from_pretrained(model, \"output_qwen/\")\n",
    "merged_model = model.merge_and_unload()\n",
    "merged_model.save_pretrained(\"output_qwen_merged\", max_shard_size=\"2048MB\", safe_serialization=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "0dfbd261-6451-4532-82e8-3ae19ed93ee1",
   "metadata": {},
   "source": "## 分词器"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcba069-340b-4a93-a145-2028b425dd23",
   "metadata": {},
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"Qwen/Qwen-1_8B-Chat/\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "tokenizer.save_pretrained(\"output_qwen_merged\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "fe9f2878-79d3-4b1c-ba95-ac2f73aa6e1b",
   "metadata": {},
   "source": "## 模型测试"
  },
  {
   "cell_type": "code",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-02-26T11:49:14.690891Z"
    }
   },
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers.generation import GenerationConfig\n",
    "import torchvision\n",
    "\n",
    "torchvision.disable_beta_transforms_warning()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/root/autodl-fs/DeepSeek-R1-Distill-Llama-70B\", trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"/root/autodl-fs/DeepSeek-R1-Distill-Llama-70B\",\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ").eval()\n",
    "\n",
    "prompt = \"你好,你是谁？\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "response = tokenizer.decode(model.generate(**inputs, max_new_tokens=128000)[0], skip_special_tokens=True)\n",
    "print(response)"
   ],
   "id": "bc3f2a8586ad7424",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/17 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7524e6628bd74c919ca694e01df27152"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 选一条样本对训练出来的模型进行人工比对",
   "id": "89992b6b55790e2b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "{\n",
    "    \"conversations\": \n",
    "        [\n",
    "            {\n",
    "                \"from\": \"user\", \n",
    "                \"value\": \"你现在是一个很厉害的阅读理解器，严格按照人类指令进行回答。\\nInput: 下面描述中包含了哪些SPO？\\n返回json回答:\\n\\n花样男子花样男子《花样男子》，日文原名《花より男子》（Hana-yori Danshi），是日本漫画家神尾叶子的一部长篇爱情校园漫画，原作自1992年至2004年在集英社的漫画杂志《Margaret》上连载，并发行了37册的单行本，销量超过5900万册，霸占了日本第一畅销少女漫画的宝座。\"}, \n",
    "            {\n",
    "                \"from\": \"assistant\", \n",
    "                \"value\": \"[{\\\"predicate\\\": \\\"编剧\\\", \\\"object_type\\\": \\\"人物\\\", \\\"subject_type\\\": \\\"影视作品\\\", \\\"object\\\": \\\"神尾叶子\\\", \\\"subject\\\": \\\"花样男子\\\"}, {\\\"predicate\\\": \\\"出版社\\\", \\\"object_type\\\": \\\"出版社\\\", \\\"subject_type\\\": \\\"书籍\\\", \\\"object\\\": \\\"集英社\\\", \\\"subject\\\": \\\"花样男子\\\"}]\"\n",
    "            }\n",
    "        ], \n",
    "    \"id\": \"identity_0\"\n",
    "}"
   ],
   "id": "6aceadf2c3883c9b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
